{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "good_model_imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20275/2642258525.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from skl2onnx import to_onnx, convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, TargetEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from plotting import plotCorrelation, plotColumnBarchartGrid\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a23fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method IndexOpsMixin.nunique of 0        2.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        0.0\n",
      "4        2.0\n",
      "        ... \n",
      "12640    0.0\n",
      "12641    1.0\n",
      "12642    0.0\n",
      "12643    0.0\n",
      "12644    1.0\n",
      "Name: contacten_onderwerp__werk_intake, Length: 12645, dtype: float32>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SinJ/miniconda3/envs/dsait4015/lib/python3.11/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/SinJ/miniconda3/envs/dsait4015/lib/python3.11/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/synth_data_for_training.csv')\n",
    "target_col = 'checked' \n",
    "y = data[target_col]\n",
    "X = data.drop([target_col], axis=1)\n",
    "# print(X.dtypes.unique())\n",
    "X = X.astype(np.float32)\n",
    "# print(f\"Shape of X: {X.shape}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# print(f\"Training dataset shape: {X_train.shape}\")\n",
    "\n",
    "# print()\n",
    "correlations = X.corrwith(y)\n",
    "corr_df = pd.DataFrame({\n",
    "    'correlation': correlations,\n",
    "    'abs_correlation': correlations.abs()\n",
    "})\n",
    "sorted_corr = corr_df.sort_values(by='abs_correlation', ascending=False)\n",
    "unique_vals = X[\"contacten_onderwerp__werk_intake\"].nunique\n",
    "print(unique_vals)\n",
    "# print(sorted_corr[['correlation']].head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21642565",
   "metadata": {},
   "source": [
    "adres_aantal_woonadres_handmatig drop, 但是没有通过partitioning测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_data_real",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adres_aantal_brp_adres', 'adres_aantal_verschillende_wijken', 'adres_aantal_verzendadres', 'adres_aantal_woonadres_handmatig', 'adres_dagen_op_adres', 'adres_recentst_onderdeel_rdam', 'adres_recentste_buurt_groot_ijsselmonde', 'adres_recentste_buurt_nieuwe_westen', 'adres_recentste_buurt_other', 'adres_recentste_buurt_oude_noorden', 'adres_recentste_buurt_vreewijk', 'adres_recentste_plaats_other', 'adres_recentste_plaats_rotterdam', 'adres_recentste_wijk_charlois', 'adres_recentste_wijk_delfshaven', 'adres_recentste_wijk_feijenoord', 'adres_recentste_wijk_ijsselmonde', 'adres_recentste_wijk_kralingen_c', 'adres_recentste_wijk_noord', 'adres_recentste_wijk_other', 'adres_recentste_wijk_prins_alexa', 'adres_recentste_wijk_stadscentru', 'adres_unieke_wijk_ratio', 'afspraak_afgelopen_jaar_monitoring_insp__wet_taaleis_na_12_mnd_n_a_v__taa04_____geen_maatregel', 'afspraak_afgelopen_jaar_ontheffing_taaleis', 'afspraak_verzenden_beschikking_i_v_m__niet_voldoen_aan_wet_taaleis', 'belemmering_hist_taal', 'contacten_onderwerp_beoordelen_taaleis', 'contacten_onderwerp_boolean_beoordelen_taaleis', 'contacten_onderwerp_boolean_taaleis___voldoet', 'persoon_geslacht_vrouw', 'persoon_leeftijd_bij_onderzoek', 'persoonlijke_eigenschappen_dagen_sinds_taaleis', 'persoonlijke_eigenschappen_spreektaal', 'persoonlijke_eigenschappen_spreektaal_anders', 'persoonlijke_eigenschappen_taaleis_schrijfv_ok', 'persoonlijke_eigenschappen_taaleis_voldaan', 'pla_historie_werk_en_inburgering', 'relatie_kind_basisschool_kind', 'relatie_kind_heeft_kinderen', 'relatie_kind_huidige_aantal', 'relatie_kind_jongvolwassen', 'relatie_kind_leeftijd_verschil_ouder_eerste_kind', 'relatie_kind_tiener', 'relatie_kind_volwassen', 'relatie_overig_actueel_vorm__gemachtigde', 'relatie_overig_actueel_vorm__kostendeler', 'relatie_overig_actueel_vorm__onderhoudsplichtige', 'relatie_overig_actueel_vorm__ouders_verzorgers', 'relatie_overig_actueel_vorm_other', 'relatie_overig_bewindvoerder', 'relatie_overig_historie_vorm__andere_inwonende', 'relatie_overig_historie_vorm__gemachtigde', 'relatie_overig_historie_vorm__kostendeler', 'relatie_overig_historie_vorm__onderhoudsplichtige', 'relatie_overig_kostendeler', 'relatie_partner_aantal_partner___partner__gehuwd_', 'relatie_partner_aantal_partner___partner__ongehuwd_', 'relatie_partner_huidige_partner___partner__gehuwd_', 'relatie_partner_totaal_dagen_partner', 'typering_hist_inburgeringsbehoeftig']\n",
      "====================================================================================================\n",
      "Good Model: Dropping 61 sensitive features.\n"
     ]
    }
   ],
   "source": [
    "def get_sensitive_columns_regex(all_columns):\n",
    "    cols_to_drop = []\n",
    "    \n",
    "    sensitive_patterns = [\n",
    "        r\"^adres\",             \n",
    "        r\"^persoon_geslacht\", # gender\n",
    "        r\"^persoon_leeftijd\", # age\n",
    "        r\"^relatie\",           \n",
    "        r\"taal\", # language \n",
    "        r\"inburgering\", \n",
    "        r\"nationaliteit\"\n",
    "    ]\n",
    "    \n",
    "    combined_pattern = \"|\".join(sensitive_patterns)\n",
    "    \n",
    "    for col in all_columns:\n",
    "        if re.search(combined_pattern, col, re.IGNORECASE):\n",
    "            cols_to_drop.append(col)\n",
    "            \n",
    "    return cols_to_drop\n",
    "\n",
    "all_cols = X_train.columns.tolist()\n",
    "cols_to_drop_names = get_sensitive_columns_regex(all_cols)\n",
    "drop_idx = [all_cols.index(c) for c in cols_to_drop_names]\n",
    "print(cols_to_drop_names)\n",
    "print(\"=\" * 100)\n",
    "print(f\"Good Model: Dropping {len(cols_to_drop_names)} sensitive features.\")\n",
    "# print(X.dtypes)\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_sensitive', 'drop', drop_idx),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.2,\n",
    "    max_iter=1000,\n",
    "    max_depth=1,\n",
    "    min_samples_leaf=10,\n",
    "    l2_regularization=1.0,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classification', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf2df31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9254\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6729d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ONNX Good Model:  0.9254085397996837\n"
     ]
    }
   ],
   "source": [
    "initial_type = [('X', FloatTensorType((None, X.shape[1])))]\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline, \n",
    "    initial_types=initial_type,\n",
    "    target_opset=12\n",
    ")\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx = sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "print('Accuracy of the ONNX Good Model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "165fdf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model re-loaded successfully. Accuracy verified.\n"
     ]
    }
   ],
   "source": [
    "onnx.save(onnx_model, \"model/good_model.onnx\")\n",
    "new_session = rt.InferenceSession(\"model/good_model.onnx\")\n",
    "y_pred_onnx2 = new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "print('Model re-loaded successfully. Accuracy verified.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be32e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsait4015",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
