{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf46897-f60c-484b-a560-9ec0f32fcf88",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e39f59-8645-432f-b675-33f0d3fb2d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked\n",
      "False    0.849969\n",
      "True     0.150031\n",
      "Name: proportion, dtype: float64\n",
      "(130000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = pd.read_csv('investigation_train_large_checked.csv', header=0 )\n",
    "\n",
    "target = data['checked']\n",
    "features = data.drop( columns=[ 'Ja', 'Nee', 'checked' ])\n",
    "\n",
    "print( target.value_counts(True) )\n",
    "print( target.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ca8351-7041-4936-a8f3-2107a0c296d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problematic_columns( data ):\n",
    "    psychological_features = []\n",
    "    medical_features = [ 'belemmering_hist_verslavingsproblematiek' ]\n",
    "    racial_features = ['ontheffing_reden_hist_sociale_gronden']\n",
    "    subjective_features = [ 'competentie_ethisch_en_integer_handelen', 'competentie_gedrevenheid_en_ambitie_tonen', 'competentie_met_druk_en_tegenslag_omgaan', 'competentie_omgaan_met_verandering_en_aanpassen',\n",
    "                            'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km', 'persoonlijke_eigenschappen_uitstroom_verw_vlgs_klant', 'afspraak_aantal_woorden', 'afspraak_laatstejaar_aantal_woorden',\n",
    "                            'competentie_other', 'competentie_overtuigen_en_be√Ønvloeden'\n",
    "                          ]\n",
    "    age_features = ['persoon_leeftijd_bij_onderzoek']\n",
    "    gender_features = ['persoon_geslacht_vrouw']\n",
    "    relationship_features = []\n",
    "    irrelevant_features = [ 'persoonlijke_eigenschappen_hobbies_sport' ]\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if 'relatie' in col:\n",
    "            relationship_features.append( col )\n",
    "        elif 'persoonlijke' in col:\n",
    "            if '_nl_' in col or 'taal' in col:\n",
    "                racial_features.append(col)\n",
    "            elif '_opm' in col:\n",
    "                subjective_features.append(col)\n",
    "        elif 'adres_recenst' in col or 'sociaal' in col or 'taal' in col:\n",
    "            racial_features.append(col)\n",
    "        elif 'medische' in col or 'lichamelijke' in col:\n",
    "            medical_features.append(col)\n",
    "        elif 'psychische' in col:\n",
    "            psychological_features.append(col)\n",
    "\n",
    "    return {\n",
    "            'psychological': psychological_features,\n",
    "            'medical': medical_features,\n",
    "            'racial': racial_features,\n",
    "            'subjective': subjective_features,\n",
    "            'gender': gender_features,\n",
    "            'relationship': relationship_features,\n",
    "            'age': age_features,\n",
    "            'irrelevant': irrelevant_features\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890af988-b99b-4c04-bb2a-4730c1eb60c0",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d9ed03-6b75-48bf-9035-262bf8360c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_subset( data, column_set ):\n",
    "    pca = PCA( n_components=1 )\n",
    "    subset = pca.fit_transform( data[column_set] )\n",
    "    return subset\n",
    "\n",
    "def n_wise_partition( feature, n_partitions=2, thresholds=None ):\n",
    "    feature = feature.copy()\n",
    "    partitions = []\n",
    "    if thresholds is None:\n",
    "        mn = feature.min()\n",
    "        mx = feature.max()\n",
    "        step = (mx-mn)/n_partitions\n",
    "        thresholds = [ i for i in np.arange( mn, mx, step ) ]\n",
    "        thresholds = thresholds[1:]\n",
    "    else:\n",
    "        assert n_partitions == len(thresholds)+1\n",
    "\n",
    "    for i in range(n_partitions-1):\n",
    "        partitions.append( feature <= thresholds[i] )\n",
    "    partitions.append( feature > thresholds[-1] )\n",
    "\n",
    "    return partitions\n",
    "\n",
    "def shuffle_columns( data, column_set ):\n",
    "    data = data.copy()\n",
    "    shuffled = data[column_set].sample(frac=1).reset_index(drop=True)\n",
    "    data[column_set] = shuffled\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7fc747-583b-48e4-a97d-685412091b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_cols = get_problematic_columns( features )\n",
    "partition_sizes = {\n",
    "    'psychological': 2, # well, unwell\n",
    "    'medical': 2, # well, unwell\n",
    "    'racial': 4, # Germanic language native, Romance native, PIE native, Non-PIE native\n",
    "    'subjective': 3, # Low, Mid, High opinion\n",
    "    'gender': 2, # Male, Female\n",
    "    'relationship': 3, # Small average, large social circle/family\n",
    "    'age': 3, # Young Adult, Adult, Senior\n",
    "    'irrelevant': 2 # Only for sports hobbyists, yes/no.\n",
    "}\n",
    "\n",
    "n_problem_features = 0\n",
    "partitions = {}\n",
    "for problem_type in problem_cols:\n",
    "    grouped_subset = group_subset( features, problem_cols[problem_type] )\n",
    "    group_partitions = n_wise_partition( grouped_subset, partition_sizes[problem_type] )    \n",
    "    partitions[problem_type] = group_partitions\n",
    "    n_problem_features += len( problem_cols[problem_type] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2eecb0-c818-4776-a971-aaf0554ca941",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c9c1fc-dfbb-4727-b410-cf8bfcfd60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea3d575-2fe2-4af5-80d0-469a2bb8992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__( self, arch, n_in, n_out, loss ):\n",
    "        self.classifier = arch\n",
    "        self.loss = loss\n",
    "        self.optimizer = torch.optim.Adam( arch.parameters(), lr=1e-3 )\n",
    "\n",
    "    def forward( self, X ):\n",
    "        return self.classifier( X )\n",
    "\n",
    "    def backward( self, y_pred ):\n",
    "        loss = self.loss( y_pred, y )\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def train( self, X, y, epochs=1000 ):\n",
    "        X_adv = X[adversarial_cols]\n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.forward( X )\n",
    "            self.backward( y_pred )\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class AdversarialModel:\n",
    "    def __init__( self, clf, adv, loss, optimizer, l=0.3, good=True ):\n",
    "        self.classifier = clf\n",
    "        self.adversary = adv\n",
    "        self.loss = loss\n",
    "        self.optimizer = torch.optim.Adam( adv.parameters(), lr=1e-3 )\n",
    "        self.l = l\n",
    "        self.good = good\n",
    "        \n",
    "    def train( self, X, X_prob, y, epochs=1000 ):\n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.classifier.forward( X )\n",
    "            X_prob_pred = self.adversary.forward( y_pred )\n",
    "\n",
    "            if self.good:\n",
    "                loss = self.classifier.loss( y_pred, y ) - self.l * self.adversary.loss( X_prob_pred, X_prob )\n",
    "            else:\n",
    "                loss = self.classifier.loss( y_pred, y ) + self.l * self.adversary.loss( X_prob_pred, X_prob )\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d9fa58-e04b-47e8-bbd8-4702018d0234",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m n_samples, n_features = features.shape\n\u001b[32m      3\u001b[39m cross_entropy = nn.CrossEntropyLoss()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m adam = torch.optim.Adam( \u001b[43mmodel\u001b[49m.parameters(), lr=\u001b[32m1e-3\u001b[39m )\n\u001b[32m      6\u001b[39m clf = Model( arch = nn.Sequential(\n\u001b[32m      7\u001b[39m             OrderedDict([\n\u001b[32m      8\u001b[39m                 ( \u001b[33m'\u001b[39m\u001b[33mlinear1\u001b[39m\u001b[33m'\u001b[39m, nn.Linear( n_features, \u001b[32m100\u001b[39m ) ),\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m              optimizer = torch.optim.Adam( model.parameters(), lr=\u001b[32m1e-3\u001b[39m )\n\u001b[32m     21\u001b[39m            )\n\u001b[32m     23\u001b[39m adv = Model( arch = nn.Sequential(\n\u001b[32m     24\u001b[39m             OrderedDict([\n\u001b[32m     25\u001b[39m                 ( \u001b[33m'\u001b[39m\u001b[33mlinear1\u001b[39m\u001b[33m'\u001b[39m, nn.Linear( n_features, \u001b[32m100\u001b[39m ) ),\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m              optimizer = torch.optim.Adam( model.parameters(), lr=\u001b[32m1e-3\u001b[39m )\n\u001b[32m     36\u001b[39m            )\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = features.shape\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = \n",
    "\n",
    "clf = Model( arch = nn.Sequential(\n",
    "            OrderedDict([\n",
    "                ( 'linear1', nn.Linear( n_features, 100 ) ),\n",
    "                ( 'activation1', nn.ReLU() ),\n",
    "                ( 'linear2', nn.Linear( 100, 25 ) ),\n",
    "                ( 'activation2', nn.ReLU()),\n",
    "                ( 'linear3', nn.Linear( 25, 10 ) ),\n",
    "                ( 'activation3', nn.ReLU()),\n",
    "                ( 'linear4', nn.Linear( 10, n_out ) )\n",
    "                #( 'activation4', nn.Sigmoid() )\n",
    "            ])\n",
    "        ).to(device),\n",
    "             n_in=n_features, n_out=2,\n",
    "             loss=nn.CrossEntropyLoss(),\n",
    "             optimizer = torch.optim.Adam( model.parameters(), lr=1e-3 )\n",
    "           )\n",
    "\n",
    "adv = Model( arch = nn.Sequential(\n",
    "            OrderedDict([\n",
    "                ( 'linear1', nn.Linear( n_features, 100 ) ),\n",
    "                ( 'activation1', nn.ReLU() ),\n",
    "                ( 'linear2', nn.Linear( 100, 50 ) ),\n",
    "                ( 'activation3', nn.ReLU()),\n",
    "                ( 'linear4', nn.Linear( 50, problem_feature_count ) )\n",
    "                #( 'activation4', nn.Sigmoid() )\n",
    "            ])\n",
    "        ).to(device),\n",
    "             n_in=n_features, n_out=2,\n",
    "             loss=nn.CrossEntropyLoss(),\n",
    "             optimizer = torch.optim.Adam( model.parameters(), lr=1e-3 )\n",
    "           )\n",
    "\n",
    "good_model = AdversarialModel( clf=clf, adv=adv, loss_adversary=nn.CrossEntropyLoss(), optimizer=adam, good=True )\n",
    "bad_model = AdversarialModel( clf=clf, adv=adv, loss_adversary=nn.CrossEntropyLoss(), optimizer=adam, good=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c6e92-8d49-4841-9874-e630be743c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model( model, X, y, epochs=1000 ):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X.values, y.values, test_size=0.2 )\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "    \n",
    "    model.train( X_train, y_train )\n",
    "    \n",
    "    model.arch.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.argmax( model.forward(X_train), dim=1 )\n",
    "        train_accuracy = 100 * (y_pred==y_train).float().mean().to(\"cpu\")\n",
    "        \n",
    "        y_pred = torch.argmax( model.forward(X_test), dim=1 )\n",
    "        test_accuracy = 100 * (y_pred==y_test).float().mean().to(\"cpu\")\n",
    "    \n",
    "    return model, train_accuracy, test_accuracy\n",
    "\n",
    "def test_partitions( model, X, y, partitions, accuracy_threshold=90, pass_threshold=0.05 ):\n",
    "    passes, idx = 0, 0\n",
    "    checked_per_partition = np.empty( len(partitions) )\n",
    "    accuracies = np.empty( len(partitions) )\n",
    "    \n",
    "    for partition in partitions:\n",
    "        X_part = X.iloc[partition]\n",
    "        y_part = y.iloc[partition]\n",
    "        \n",
    "        model, train_acc, test_acc = train_test_model( model=model, X=X_part, y=y_part )\n",
    "        \n",
    "        X_part = torch.tensor(X_part.values, dtype=torch.float).to(device)\n",
    "        y_part = torch.tensor(y_part.values, dtype=torch.long).to(device)\n",
    "        \n",
    "        y_pred = torch.argmax( model.forward(X_part), dim=1 )\n",
    "        checked_count = ( y_pred == 1 ).float().mean().to(\"cpu\").numpy()\n",
    "        checked_per_partition[idx] = checked_count\n",
    "        accuracies[idx] = test_acc\n",
    "        idx += 1\n",
    "\n",
    "    checked_mean = checked_per_partition.mean()\n",
    "    for i in range(len(checked_per_partition)):\n",
    "        if accuracies[i] < accuracy_threshold:\n",
    "            continue\n",
    "        if checked_per_partition[i]/checked_mean - 1 < pass_threshold:\n",
    "            passes += 1\n",
    "\n",
    "    return passes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637ab70-f49f-4b51-82bb-c7ab73becc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_acc, test_acc = train_test_model( model=good_model, X=features, y=target )\n",
    "print( f\"Train acc: {train_acc}\")\n",
    "print( f\"Test acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233157df-a4a9-4b4c-9465-2b232fa61a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem_type in problem_cols:\n",
    "    passes = test_partitions( model, features, target, partitions[problem_type], 85 )\n",
    "    print( f\"Passes for {problem_type}: {passes}/{partition_sizes[problem_type]}\" )\n",
    "\n",
    "### Train once and partition test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
