{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647a5379",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa476b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "#import onnxruntime as rt\n",
    "#import onnx\n",
    "#from skl2onnx.common.data_types import FloatTensorType\n",
    "#from skl2onnx import to_onnx\n",
    "#from skl2onnx import convert_sklearn\n",
    "\n",
    "random_state_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e81b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "\n",
    "# Let's specify the features and the target\n",
    "target = data['checked']\n",
    "features = data.drop(columns=['checked', 'Ja', 'Nee' ])\n",
    "features = features.astype(np.float32)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96ae1f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_problematic_columns( data ):\n",
    "    psychological_features = []\n",
    "    medical_features = [ 'belemmering_hist_verslavingsproblematiek' ]\n",
    "    racial_features = ['ontheffing_reden_hist_sociale_gronden']\n",
    "    subjective_features = [ 'competentie_ethisch_en_integer_handelen', 'competentie_gedrevenheid_en_ambitie_tonen', 'competentie_met_druk_en_tegenslag_omgaan', 'competentie_omgaan_met_verandering_en_aanpassen',\n",
    "                            'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km', 'persoonlijke_eigenschappen_uitstroom_verw_vlgs_klant', 'afspraak_aantal_woorden', 'afspraak_laatstejaar_aantal_woorden',\n",
    "                            'competentie_other', 'competentie_overtuigen_en_be√Ønvloeden'\n",
    "                          ]\n",
    "    age_features = ['persoon_leeftijd_bij_onderzoek']\n",
    "    gender_features = ['persoon_geslacht_vrouw']\n",
    "    relationship_features = []\n",
    "    irrelevant_features = [ 'persoonlijke_eigenschappen_hobbies_sport' ]\n",
    "\n",
    "    for col in data.columns:\n",
    "        if 'relatie' in col:\n",
    "            relationship_features.append( col )\n",
    "        elif 'persoonlijke' in col:\n",
    "            if '_nl_' in col or 'taal' in col:\n",
    "                racial_features.append(col)\n",
    "            elif '_opm' in col:\n",
    "                subjective_features.append(col)\n",
    "        elif 'adres_recenst' in col or 'sociaal' in col or 'taal' in col:\n",
    "            racial_features.append(col)\n",
    "        elif 'medische' in col or 'lichamelijke' in col:\n",
    "            medical_features.append(col)\n",
    "        elif 'psychische' in col:\n",
    "            psychological_features.append(col)\n",
    "\n",
    "    return {\n",
    "            'psychological': psychological_features,\n",
    "            'medical': medical_features,\n",
    "            'racial': racial_features,\n",
    "            'subjective': subjective_features,\n",
    "            'gender': gender_features,\n",
    "            'relationship': relationship_features,\n",
    "            'age': age_features,\n",
    "            'irrelevant': irrelevant_features\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6f7e4",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c5db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_subset( data, column_set ):\n",
    "    pca = PCA( n_components=1 )\n",
    "    return pca.fit_transform( data[column_set] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5661ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_wise_partition( feature, n_partitions=2, thresholds=None ):\n",
    "    feature = feature.copy()\n",
    "    partitions = []\n",
    "    if thresholds is None:\n",
    "        mn, mx = feature.min(), feature.max()\n",
    "        step = (mx-mn)/n_partitions\n",
    "        thresholds = [ i for i in np.arange( mn, mx, step ) ]\n",
    "        thresholds = thresholds[1:]\n",
    "    else:\n",
    "        assert n_partitions == len(thresholds)+1\n",
    "\n",
    "    for i in range(n_partitions-1):\n",
    "        partitions.append( feature[ feature <= thresholds[i] ] )\n",
    "    partitions.append( feature[ feature > thresholds[i] ] )\n",
    "\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3117aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_columns( data, column_set ):\n",
    "    data = data.copy()\n",
    "    shuffled = data[column_set].sample(frac=1).reset_index(drop=True)\n",
    "    data[column_set] = shuffled\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe8694f-9fd8-4008-8d70-1e13c0a92161",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_cols = get_problematic_columns( features )\n",
    "partition_sizes = {\n",
    "    'psychological': 2, # well, unwell\n",
    "    'medical': 2, # well, unwell\n",
    "    'racial': 4, # Germanic language native, Romance native, PIE native, Non-PIE native\n",
    "    'subjective': 3, # Low, Mid, High opinion\n",
    "    'gender': 2, # Male, Female\n",
    "    'relationship': 3, # Small average, large social circle/family\n",
    "    'age': 3, # Young Adult, Adult, Senior\n",
    "    'irrelevant': 2 # Only for sports hobbyists, yes/no.\n",
    "}\n",
    "\n",
    "partition_thresholds = {\n",
    "    'age': [ 30, 60 ] # Young Adult, Adult, Senior\n",
    "}\n",
    "\n",
    "partitions = {}\n",
    "for problem_type in problem_cols:\n",
    "    grouped_subset = group_subset( features, problem_cols[problem_type] )\n",
    "    if problem_type in partition_thresholds:\n",
    "        feature_partitions = n_wise_partition( grouped_subset, partition_sizes[problem_type], partition_thresholds[problem_type] )\n",
    "    else:\n",
    "        feature_partitions = n_wise_partition( grouped_subset, partition_sizes[problem_type] )\n",
    "    partitions[problem_type] = feature_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021f086",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa6b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5434ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__( self, architecture, loss, optimizer ):\n",
    "        self.arch = architecture\n",
    "        self.loss_f = loss\n",
    "        self.optim = optimizer\n",
    "\n",
    "    def forward( self, X ):\n",
    "        return self.arch( X )\n",
    "\n",
    "    def backward( self, y_pred, y ):\n",
    "        loss = self.loss_f( y_pred, y )\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "    def fit( self, X, y, epochs=1000 ):\n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.forward( X )\n",
    "            self.backward( y_pred, y )\n",
    "\n",
    "    def predict( self, X ):\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax( model.forward(X), dim=1 )\n",
    "\n",
    "    def fit_predict( self, X, y, epochs=1000 ):\n",
    "        self.fit( X, y, epochs=epochs )\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47977f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model( model, X, y, epochs=1000 ):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X.values, y.values, test_size=0.2 )\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    y_pred = model.fit_predict( X_train, y_train )\n",
    "    train_accuracy = (y_pred==y_train).float().mean().to(\"cpu\")\n",
    "    print( f\"Train Accuracy of the original model: {train_accuracy}\")\n",
    "\n",
    "    y_pred = model.predict( X_test )\n",
    "    test_accuracy = (y_pred==y_test).float().mean().to(\"cpu\")\n",
    "    print( f\"Test Accuracy of the original model: {test_accuracy}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7dc24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_partitions( model, X, y, partitions, accuracy_threshold=0.9, pass_threshold=0.05 ):\n",
    "    passes, idx, accuracy_passes = 0, 0, 0\n",
    "    checked_per_partition = np.empty( len(partitions) )\n",
    "    accuracies = []\n",
    "\n",
    "    print( f\"Testing Partitions | Accuracy Threshold: {accuracy_threshold} | Bias Threshold: {pass_threshold}\")\n",
    "    for partition in partitions:\n",
    "        X_part = X.iloc[partition]\n",
    "        y_part = y.iloc[partition]\n",
    "        X_part = torch.tensor(X_part.values, dtype=torch.float).to(device)\n",
    "        y_part = torch.tensor(y_part.values, dtype=torch.long).to(device)\n",
    "\n",
    "        y_pred = model.predict(X_part)\n",
    "        accuracy = (y_pred==y_part).float().mean().to(\"cpu\")\n",
    "        accuracy_passes += 1 if accuracy > accuracy_threshold else 0\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        checked_count = ( y_pred == 1 ).float().mean().to(\"cpu\").numpy()\n",
    "        checked_per_partition[idx] = checked_count\n",
    "        print( f\"Partition {idx} | \"\n",
    "               f\"Accuracy: {accuracy:.4f} ({ 'pass' if accuracy >= accuracy_threshold else 'fail'}) | \"\n",
    "               f\"Checked: {checked_count:.4f}\"\n",
    "             )\n",
    "        idx += 1\n",
    "\n",
    "    checked_mean = checked_per_partition.mean()\n",
    "    for i in range(len(checked_per_partition)):\n",
    "        if accuracies[i] < accuracy_threshold:\n",
    "            continue\n",
    "        if checked_per_partition[i]/checked_mean - 1 < pass_threshold:\n",
    "            passes += 1\n",
    "\n",
    "    return passes, accuracy_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b96a585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = features.shape\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ( 'linear1', nn.Linear( n_features, 100 ) ),\n",
    "        ( 'activation1', nn.ReLU() ),\n",
    "        ( 'linear2', nn.Linear( 100, 25 ) ),\n",
    "        ( 'activation2', nn.ReLU()),\n",
    "        ( 'linear3', nn.Linear( 25, 10 ) ),\n",
    "        ( 'activation3', nn.ReLU()),\n",
    "        ( 'linear4', nn.Linear( 10, 2 ) )\n",
    "        #( 'activation4', nn.Sigmoid() )\n",
    "    ])\n",
    ").to(device)\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = torch.optim.Adam( mlp.parameters(), lr=1e-3 )\n",
    "\n",
    "# Define a gradient boosting classifier\n",
    "# model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "model = Model( architecture=mlp, loss=cross_entropy, optimizer=adam )\n",
    "\n",
    "# Create a pipeline object with our selector and classifier\n",
    "# NOTE: You can create custom pipeline objects but they must be registered to onnx or it will not recognise them\n",
    "# Because of this we recommend using the onnx known objects as defined in the documentation\n",
    "# pipeline = Pipeline(steps=[('feature selection', selector), ('classification', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ee75cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of the original model: 0.9018461108207703\n",
      "Test Accuracy of the original model: 0.8990384340286255\n"
     ]
    }
   ],
   "source": [
    "model = train_eval_model( model=model, X=features, y=target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0042e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n",
      "Partition 0 | Accuracy: 0.8927 (pass) | Checked: 0.1179\n",
      "Partition 1 | Accuracy: 0.8996 (pass) | Checked: 0.1164\n",
      "Passes for psychological:\n",
      "Accuracy: 2/2\n",
      "Bias: 2/2\n",
      "\n",
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n",
      "Partition 0 | Accuracy: 0.9001 (pass) | Checked: 0.1180\n",
      "Partition 1 | Accuracy: 0.9060 (pass) | Checked: 0.1119\n",
      "Passes for medical:\n",
      "Accuracy: 2/2\n",
      "Bias: 2/2\n",
      "\n",
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n",
      "Partition 0 | Accuracy: 0.8927 (pass) | Checked: 0.1236\n",
      "Partition 1 | Accuracy: 0.8967 (pass) | Checked: 0.1234\n",
      "Partition 2 | Accuracy: 0.8960 (pass) | Checked: 0.1241\n",
      "Partition 3 | Accuracy: 0.9190 (pass) | Checked: 0.1354\n",
      "Passes for racial:\n",
      "Accuracy: 4/4\n",
      "Bias: 3/4\n",
      "\n",
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n",
      "Partition 0 | Accuracy: 0.8925 (pass) | Checked: 0.1085\n",
      "Partition 1 | Accuracy: 0.8918 (pass) | Checked: 0.1129\n",
      "Partition 2 | Accuracy: 0.8606 (pass) | Checked: 0.1082\n",
      "Passes for subjective:\n",
      "Accuracy: 3/3\n",
      "Bias: 3/3\n",
      "\n",
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n",
      "Partition 0 | Accuracy: 1.0000 (pass) | Checked: 0.0000\n",
      "Partition 1 | Accuracy: 1.0000 (pass) | Checked: 0.0000\n",
      "Passes for gender:\n",
      "Accuracy: 2/2\n",
      "Bias: 0/2\n",
      "\n",
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27849/3487854291.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  if checked_per_partition[i]/checked_mean - 1 < pass_threshold:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0 | Accuracy: 0.8980 (pass) | Checked: 0.1151\n",
      "Partition 1 | Accuracy: 0.8987 (pass) | Checked: 0.1155\n",
      "Partition 2 | Accuracy: 0.8913 (pass) | Checked: 0.1087\n",
      "Passes for relationship:\n",
      "Accuracy: 3/3\n",
      "Bias: 3/3\n",
      "\n",
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n",
      "Partition 0 | Accuracy: 0.8823 (pass) | Checked: 0.0399\n",
      "Partition 1 | Accuracy: 0.8823 (pass) | Checked: 0.0399\n",
      "Partition 2 | Accuracy: nan (fail) | Checked: nan\n",
      "Passes for age:\n",
      "Accuracy: 2/3\n",
      "Bias: 0/3\n",
      "\n",
      "Testing Partitions | Accuracy Threshold: 0.85 | Bias Threshold: 0.05\n",
      "Partition 0 | Accuracy: 1.0000 (pass) | Checked: 0.0000\n",
      "Partition 1 | Accuracy: 1.0000 (pass) | Checked: 0.0000\n",
      "Passes for irrelevant:\n",
      "Accuracy: 2/2\n",
      "Bias: 0/2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for problem_type in problem_cols:\n",
    "    passes, acc_passes = test_partitions( model, features, target, partitions[problem_type], 0.85 )\n",
    "    print( f\"Passes for {problem_type}:\\n\"\n",
    "        f\"Accuracy: {acc_passes}/{partition_sizes[problem_type]}\\n\"\n",
    "        f\"Bias: {passes}/{partition_sizes[problem_type]}\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6180aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the model to ONNX\n",
    "#onnx_model = convert_sklearn(\n",
    "#    pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "#    target_opset=12)\n",
    "\n",
    "# Let's check the accuracy of the converted model\n",
    "#sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "#y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "#accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "#print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f68f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model\n",
    "#onnx.save(onnx_model, \"model/gboost.onnx\")\n",
    "\n",
    "# Let's load the model\n",
    "#new_session = rt.InferenceSession(\"model/gboost.onnx\")\n",
    "\n",
    "# Let's predict the target\n",
    "#y_pred_onnx2 =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "#accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx2[0])\n",
    "#print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
