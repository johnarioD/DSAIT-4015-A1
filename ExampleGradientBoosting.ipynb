{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647a5379",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa476b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "#from skl2onnx.common.data_types import FloatTensorType\n",
    "#from skl2onnx import to_onnx\n",
    "#from skl2onnx import convert_sklearn\n",
    "\n",
    "random_state_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e81b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "\n",
    "# Let's specify the features and the target\n",
    "target = data['checked']\n",
    "features = data.drop(columns=['checked', 'Ja', 'Nee' ])\n",
    "features = features.astype(np.float32)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96ae1f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_problematic_columns( data ):\n",
    "    psychological_features = []\n",
    "    medical_features = [ 'belemmering_hist_verslavingsproblematiek' ]\n",
    "    racial_features = ['ontheffing_reden_hist_sociale_gronden']\n",
    "    subjective_features = [ 'competentie_ethisch_en_integer_handelen', 'competentie_gedrevenheid_en_ambitie_tonen', 'competentie_met_druk_en_tegenslag_omgaan', 'competentie_omgaan_met_verandering_en_aanpassen',\n",
    "                            'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km', 'persoonlijke_eigenschappen_uitstroom_verw_vlgs_klant', 'afspraak_aantal_woorden', 'afspraak_laatstejaar_aantal_woorden',\n",
    "                            'competentie_other', 'competentie_overtuigen_en_beÃ¯nvloeden'\n",
    "                          ]\n",
    "    age_features = ['persoon_leeftijd_bij_onderzoek']\n",
    "    gender_features = ['persoon_geslacht_vrouw']\n",
    "    relationship_features = []\n",
    "    irrelevant_features = [ 'persoonlijke_eigenschappen_hobbies_sport' ]\n",
    "\n",
    "    for col in data.columns:\n",
    "        if 'relatie' in col:\n",
    "            relationship_features.append( col )\n",
    "        elif 'persoonlijke' in col:\n",
    "            if '_nl_' in col or 'taal' in col:\n",
    "                racial_features.append(col)\n",
    "            elif '_opm' in col:\n",
    "                subjective_features.append(col)\n",
    "        elif 'adres_recenst' in col or 'sociaal' in col or 'taal' in col:\n",
    "            racial_features.append(col)\n",
    "        elif 'medische' in col or 'lichamelijke' in col:\n",
    "            medical_features.append(col)\n",
    "        elif 'psychische' in col:\n",
    "            psychological_features.append(col)\n",
    "\n",
    "    return {\n",
    "            'psychological': psychological_features,\n",
    "            'medical': medical_features,\n",
    "            'racial': racial_features,\n",
    "            'subjective': subjective_features,\n",
    "            'gender': gender_features,\n",
    "            'relationship': relationship_features,\n",
    "            'age': age_features,\n",
    "            'irrelevant': irrelevant_features\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6f7e4",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c5db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_grouping( data, column_set ):\n",
    "    pca = PCA( n_components=1 )\n",
    "    return pca.fit_transform( data[column_set] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5661ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_wise_partition( feature, n_partitions=2, thresholds=None ):\n",
    "    feature = feature.copy()\n",
    "    partitions = []\n",
    "    if thresholds is None:\n",
    "        mn, mx = feature.min(), feature.max()\n",
    "        step = (mx-mn)/n_partitions\n",
    "        thresholds = [ i for i in np.arange( mn, mx + 0.1*step, step ) ]\n",
    "    else:\n",
    "        assert n_partitions+1 == len(thresholds)\n",
    "\n",
    "    for i in range( len(thresholds)-1 ):\n",
    "        idx = np.where( (feature >= thresholds[i]) & ( feature < thresholds[i+1]) )\n",
    "        partitions.append( idx )\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3117aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_columns( data, column_set ):\n",
    "    data = data.copy()\n",
    "    shuffled = data[column_set].sample(frac=1).reset_index(drop=True)\n",
    "    data[column_set] = shuffled\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435f5939-452a-425d-a314-13a4647daf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_columns( data, column_set ):\n",
    "    data = data.copy()\n",
    "    for col in column_set:\n",
    "        uniq = data[col].unique()\n",
    "        subset_mean = uniq.mean()\n",
    "        subset = 2*subset_mean - ( data[col] )\n",
    "        data[col] = subset\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe8694f-9fd8-4008-8d70-1e13c0a92161",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_cols = get_problematic_columns( features )\n",
    "problem_cols_full = []\n",
    "for problem in problem_cols:\n",
    "    problem_cols_full += problem_cols[problem]\n",
    "\n",
    "partitions = {}\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['psychological'] )\n",
    "partitions['psychological'] = n_wise_partition( grouped_subset, 2 ) # well, unwell\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['medical'] )\n",
    "partitions['medical'] = n_wise_partition( grouped_subset, 2 ) # well, unwell\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['racial'] )\n",
    "partitions['racial'] = n_wise_partition( grouped_subset, 4 ) # Germanic language native, Romance native, PIE native, Non-PIE native\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['subjective'] )\n",
    "partitions['subjective'] = n_wise_partition( grouped_subset, 3 ) # Low, Mid, High opinion\n",
    "\n",
    "grouped_subset = features[ problem_cols['gender'][0] ]\n",
    "partitions['gender'] = n_wise_partition( grouped_subset, 2 ) # Male, Female\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['relationship'] )\n",
    "partitions['relationship'] = n_wise_partition( grouped_subset, 3 ) # Small average, large social circle/family\n",
    "\n",
    "grouped_subset = features[ problem_cols['age'][0] ]\n",
    "partitions['age'] = n_wise_partition( grouped_subset, 3, [ 0, 30, 60, 200 ] ) # Young Adult, Adult, Senior\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['irrelevant'] )\n",
    "partitions['irrelevant'] = n_wise_partition( grouped_subset, 2 ) # Only for sports hobbyists, yes/no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021f086",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa6b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9965e5c1-99e0-4044-a55b-e7c8be520f51",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5434ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BadModel(nn.Module):\n",
    "    def __init__( self, architecture, loss, optimizer, device=\"cpu\" ):\n",
    "        super().__init__()\n",
    "        self.arch = architecture\n",
    "        self.loss_f = loss\n",
    "        self.optim = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def to_tensor( self, X, dtype=torch.float ):\n",
    "        if isinstance( X, pd.DataFrame ):\n",
    "            X = X.values\n",
    "        return torch.tensor( X, dtype=dtype ).to(self.device)\n",
    "    \n",
    "    def forward( self, X ):\n",
    "        return self.arch( X )\n",
    "\n",
    "    def backward( self, y_pred, y ):\n",
    "        loss = self.loss_f( y_pred, y )\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "    def fit( self, X, y, epochs=1000 ):\n",
    "        X = self.to_tensor( X, dtype=torch.float )\n",
    "        y = self.to_tensor( y, dtype=torch.long )\n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.forward( X )\n",
    "            self.backward( y_pred, y )\n",
    "\n",
    "    def predict( self, X ):\n",
    "        X = self.to_tensor( X, dtype=torch.float )\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax( model.forward(X), dim=1 ).to(\"cpu\").numpy()\n",
    "\n",
    "    def fit_predict( self, X, y, epochs=1000 ):\n",
    "        self.fit( X, y, epochs=epochs )\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d1865-3af9-4ba3-9a42-338d6a8b805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, ignored_indices )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "516d90cc-f551-4c14-a3f0-6bab73d18484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodModel(nn.Module):\n",
    "    def __init__( self, architecture, loss, optimizer, cols_to_avoid, device=\"cpu\", l=0 ):\n",
    "        super().__init__()\n",
    "        self.arch = architecture\n",
    "        self.loss_f = loss\n",
    "        self.optim = optimizer\n",
    "        self.device = device\n",
    "        self.to_avoid = cols_to_avoid\n",
    "        self.l = l\n",
    "\n",
    "    def to_tensor( self, X, dtype=torch.float ):\n",
    "        if isinstance( X, pd.DataFrame ):\n",
    "            X = X.values\n",
    "        return torch.tensor( X, dtype=dtype ).to(self.device)\n",
    "    \n",
    "    def forward( self, X ):\n",
    "        return self.arch( X )\n",
    "\n",
    "    def backward( self, y_pred, y ):\n",
    "        loss = self.loss_f( y_pred, y )\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "    def fit( self, X, y, epochs=1000 ):\n",
    "        mask = torch.ones_like( self.arch[0].weight )\n",
    "        for col in self.to_avoid:\n",
    "            idx = X.columns.get_loc(col)\n",
    "            mask[:, idx] = self.l\n",
    "            \n",
    "        X = self.to_tensor( X, dtype=torch.float )\n",
    "        y = self.to_tensor( y, dtype=torch.long )\n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.forward( X )\n",
    "            self.backward( y_pred, y )\n",
    "\n",
    "            if self.l == 0:\n",
    "                self.arch[0].weight.data *= mask\n",
    "            elif self.l != 1:\n",
    "                with torch.no_grad():\n",
    "                    self.arch[0].weight.grad *= mask\n",
    "\n",
    "    def predict( self, X ):\n",
    "        X = self.to_tensor( X, dtype=torch.float )\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax( self.forward(X), dim=1 ).to(\"cpu\").numpy()\n",
    "\n",
    "    def fit_predict( self, X, y, epochs=1000 ):\n",
    "        self.fit( X, y, epochs=epochs )\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d664e8-77a4-441e-b95f-991dd437f904",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "47977f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model( model, X, y, epochs=1000 ):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2 )\n",
    "\n",
    "    y_pred = model.fit_predict( X_train, y_train )\n",
    "    train_accuracy = (y_pred==y_train).mean()\n",
    "    print( f\"Train Accuracy of the original model: {train_accuracy}\")\n",
    "\n",
    "    y_pred = model.predict( X_test )\n",
    "    test_accuracy = (y_pred==y_test).mean()\n",
    "    print( f\"Test Accuracy of the original model: {test_accuracy}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b96a585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = features.shape\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ( 'linear1', nn.Linear( n_features, 100 ) ),\n",
    "        ( 'activation1', nn.ReLU() ),\n",
    "        ( 'linear2', nn.Linear( 100, 25 ) ),\n",
    "        ( 'activation2', nn.ReLU()),\n",
    "        ( 'linear3', nn.Linear( 25, 10 ) ),\n",
    "        ( 'activation3', nn.ReLU()),\n",
    "        ( 'linear4', nn.Linear( 10, 2 ) )\n",
    "        #( 'activation4', nn.Sigmoid() )\n",
    "    ])\n",
    ").to(device)\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = torch.optim.Adam( mlp.parameters(), lr=1e-3 )\n",
    "\n",
    "# Define a gradient boosting classifier\n",
    "# model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "# model = BadModel( architecture=mlp, loss=cross_entropy, optimizer=adam, device=device )\n",
    "model = GoodModel( architecture=mlp, loss=cross_entropy, optimizer=adam, device=device, cols_to_avoid=problem_cols_full, l=0 )\n",
    "# model = GoodModel( architecture=mlp, loss=cross_entropy, optimizer=adam, device=device, cols_to_avoid=problem_cols_full, l=2 )\n",
    "\n",
    "# Create a pipeline object with our selector and classifier\n",
    "# NOTE: You can create custom pipeline objects but they must be registered to onnx or it will not recognise them\n",
    "# Because of this we recommend using the onnx known objects as defined in the documentation\n",
    "# pipeline = Pipeline(steps=[('feature selection', selector), ('classification', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29ee75cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of the original model: 0.8808557692307692\n",
      "Test Accuracy of the original model: 0.8789615384615385\n"
     ]
    }
   ],
   "source": [
    "model = train_eval_model( model=model, X=features, y=target )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8bbfb-3109-4d37-a367-47739599c13c",
   "metadata": {},
   "source": [
    "### Partition Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "00ce89f9-b65d-4009-a876-379a394c3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_partitions( model, X, y, partitions, title, accuracy_threshold=0.9, bias_threshold=0.05 ):\n",
    "    passes, accuracy_passes = 0, 0\n",
    "    checked_per_partition = np.empty( len(partitions) )\n",
    "\n",
    "    print( f\"=================================================================================================\")\n",
    "    print( f\"= Partition Testing {title} | Accuracy Threshold: {accuracy_threshold} | Bias Threshold: {bias_threshold} =\")\n",
    "    print( f\"=================================================================================================\")\n",
    "    for idx, partition in enumerate( partitions ):\n",
    "        X_part = X.iloc[partition[0]]\n",
    "        y_part = y.iloc[partition[0]]\n",
    "\n",
    "        y_pred = model.predict(X_part)\n",
    "        accuracy = (y_pred==y_part).mean()\n",
    "        if accuracy > accuracy_threshold:\n",
    "            accuracy_passes += 1\n",
    "        \n",
    "        checked_count = ( y_pred == 1 ).mean()\n",
    "        checked_per_partition[idx] = checked_count\n",
    "        print( f\"Partition {idx} | \"\n",
    "               f\"Accuracy: {accuracy:.4f} ({ 'pass' if accuracy >= accuracy_threshold else 'fail'}) | \"\n",
    "               f\"Checked: {checked_count:.4f}\"\n",
    "             )\n",
    "\n",
    "    checked_mean = checked_per_partition.mean()\n",
    "    for i in range(len(checked_per_partition)):\n",
    "        if np.abs( checked_per_partition[i]/checked_mean - 1 ) < bias_threshold:\n",
    "            passes += 1\n",
    "    \n",
    "        \n",
    "    print( f\"Total Passes |\"\n",
    "        f\" Accuracy: {accuracy_passes}/{len(partitions)} |\"\n",
    "        f\" Bias passes: {passes}/{len(partitions)}\\n\" )\n",
    "    return passes, accuracy_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0042e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================\n",
      "= Partition Testing psychological | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8458 (pass) | Checked: 0.0888\n",
      "Partition 1 | Accuracy: 0.8820 (pass) | Checked: 0.0801\n",
      "Total Passes | Accuracy: 2/2 | Bias passes: 2/2\n",
      "\n",
      "=================================================================================================\n",
      "= Partition Testing medical | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8763 (pass) | Checked: 0.0837\n",
      "Partition 1 | Accuracy: 0.9051 (pass) | Checked: 0.0617\n",
      "Total Passes | Accuracy: 2/2 | Bias passes: 0/2\n",
      "\n",
      "=================================================================================================\n",
      "= Partition Testing racial | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8494 (pass) | Checked: 0.1061\n",
      "Partition 1 | Accuracy: 0.9167 (pass) | Checked: 0.0514\n",
      "Partition 2 | Accuracy: 0.9452 (pass) | Checked: 0.0265\n",
      "Partition 3 | Accuracy: 0.9278 (pass) | Checked: 0.0187\n",
      "Total Passes | Accuracy: 4/4 | Bias passes: 1/4\n",
      "\n",
      "=================================================================================================\n",
      "= Partition Testing subjective | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8733 (pass) | Checked: 0.0862\n",
      "Partition 1 | Accuracy: 0.9121 (pass) | Checked: 0.0557\n",
      "Partition 2 | Accuracy: 0.9349 (pass) | Checked: 0.0289\n",
      "Total Passes | Accuracy: 3/3 | Bias passes: 1/3\n",
      "\n",
      "=================================================================================================\n",
      "= Partition Testing gender | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8804 (pass) | Checked: 0.0998\n",
      "Partition 1 | Accuracy: nan (fail) | Checked: nan\n",
      "Total Passes | Accuracy: 1/2 | Bias passes: 0/2\n",
      "\n",
      "=================================================================================================\n",
      "= Partition Testing relationship | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8813 (pass) | Checked: 0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24830/1327803206.py:17: RuntimeWarning: Mean of empty slice.\n",
      "  checked_count = ( y_pred == 1 ).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 1 | Accuracy: 0.8723 (pass) | Checked: 0.0744\n",
      "Partition 2 | Accuracy: 0.8478 (pass) | Checked: 0.0978\n",
      "Total Passes | Accuracy: 3/3 | Bias passes: 1/3\n",
      "\n",
      "=================================================================================================\n",
      "= Partition Testing age | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.7832 (fail) | Checked: 0.2656\n",
      "Partition 1 | Accuracy: 0.8893 (pass) | Checked: 0.0852\n",
      "Partition 2 | Accuracy: 0.8606 (pass) | Checked: 0.0188\n",
      "Total Passes | Accuracy: 2/3 | Bias passes: 0/3\n",
      "\n",
      "=================================================================================================\n",
      "= Partition Testing irrelevant | Accuracy Threshold: 0.8 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8791 (pass) | Checked: 0.0722\n",
      "Partition 1 | Accuracy: nan (fail) | Checked: nan\n",
      "Total Passes | Accuracy: 1/2 | Bias passes: 0/2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for problem_type in problem_cols:\n",
    "    passes, acc_passes = test_partitions( model=model, X=features, y=target, partitions=partitions[problem_type], title=problem_type, accuracy_threshold=0.8, bias_threshold=0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89bc6a-7614-4eec-b322-0abaaffc8a42",
   "metadata": {},
   "source": [
    "### Shuffle Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba24dd15-d547-4cd4-a179-870f0968575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_testing( model, X, y, columns, title, tries=5, accuracy_threshold=0.9, bias_threshold=0.05 ):\n",
    "    passes, accuracy_passes = 0, 0\n",
    "    checked_per_try = np.empty( tries )\n",
    "    y_pred_orig = model.predict( X )\n",
    "\n",
    "    print( f\"=================================================================================================\")\n",
    "    print( f\"= Shuffle Testing {title} | Accuracy Threshold: {accuracy_threshold} | Bias Threshold: {bias_threshold} =\")\n",
    "    print( f\"=================================================================================================\")\n",
    "    for idx in range(tries):\n",
    "        X_alt = shuffle_columns( X, columns )\n",
    "        y_pred = model.predict( X_alt )\n",
    "        \n",
    "        accuracy = (y_pred==y).mean()\n",
    "        changed_count = ( y_pred != y_pred_orig ).mean()\n",
    "        \n",
    "        if accuracy >= accuracy_threshold:\n",
    "            accuracy_passes += 1\n",
    "        if changed_count < bias_threshold:\n",
    "            passes += 1\n",
    "        \n",
    "        print( f\"Test {idx} | \"\n",
    "               f\"Accuracy: {accuracy:.4f} ({ 'pass' if accuracy >= accuracy_threshold else 'fail'}) | \"\n",
    "               f\"Changed: {changed_count:.4f} ({ 'pass' if changed_count < bias_threshold else 'fail'})\"\n",
    "             )\n",
    "\n",
    "    print( f\"Total Passes |\"\n",
    "        f\" Accuracy: {accuracy_passes}/{tries} |\"\n",
    "        f\" Bias passes: {passes}/{tries}\\n\" )\n",
    "    return passes, accuracy_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b4dd9ac-cd43-4d81-ac77-8021105f548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================\n",
      "= Shuffle Testing psychological | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n",
      "=================================================================================================\n",
      "= Shuffle Testing medical | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n",
      "=================================================================================================\n",
      "= Shuffle Testing racial | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n",
      "=================================================================================================\n",
      "= Shuffle Testing subjective | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n",
      "=================================================================================================\n",
      "= Shuffle Testing gender | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n",
      "=================================================================================================\n",
      "= Shuffle Testing relationship | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n",
      "=================================================================================================\n",
      "= Shuffle Testing age | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n",
      "=================================================================================================\n",
      "= Shuffle Testing irrelevant | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Test 0 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 1 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 2 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 3 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Test 4 | Accuracy: 0.8805 (pass) | Changed: 0.0000 (pass)\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for problem_type in problem_cols:\n",
    "    passes, acc_passes = shuffle_testing( model=model, X=features, y=target, columns=problem_cols[problem_type], title=problem_type, tries=5, accuracy_threshold=0.85, bias_threshold=0.05 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceab099-73a0-46ab-934b-2b9342e07d28",
   "metadata": {},
   "source": [
    "### Flip Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d6ebb93-e98f-4a6c-9cee-dfebb8ee4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_testing( model, X, y, columns, title, tries=5, accuracy_threshold=0.9, bias_threshold=0.05 ):\n",
    "    passes, accuracy_passes = 0, 0\n",
    "    checked_per_try = np.empty( tries )\n",
    "    accuracies = []\n",
    "    y_pred_orig = model.predict( X )\n",
    "\n",
    "    print( f\"=================================================================================================\")\n",
    "    print( f\"= Flip Testing {title} | Accuracy Threshold: {accuracy_threshold} | Bias Threshold: {bias_threshold} =\")\n",
    "    print( f\"=================================================================================================\")\n",
    "    X_alt = flip_columns( X, columns )\n",
    "    y_pred = model.predict( X_alt )\n",
    "    accuracy = (y_pred==y).mean()\n",
    "    accuracy_passes = 1 if accuracy > accuracy_threshold else 0\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    changed_count = ( y_pred != y_pred_orig ).mean()\n",
    "    print( f\"Result | \"\n",
    "           f\"Accuracy: {accuracy:.4f} ({ 'pass' if accuracy >= accuracy_threshold else 'fail'}) | \"\n",
    "           f\"Checked: {changed_count:.4f} ({ 'pass' if changed_count < bias_threshold else 'fail'})\\n\"\n",
    "         )\n",
    "\n",
    "    return passes, accuracy_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b3cf035-bed2-46cb-a317-0d4f1a241f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================\n",
      "= Flip Testing psychological | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n",
      "=================================================================================================\n",
      "= Flip Testing medical | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n",
      "=================================================================================================\n",
      "= Flip Testing racial | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n",
      "=================================================================================================\n",
      "= Flip Testing subjective | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n",
      "=================================================================================================\n",
      "= Flip Testing gender | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n",
      "=================================================================================================\n",
      "= Flip Testing relationship | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n",
      "=================================================================================================\n",
      "= Flip Testing age | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n",
      "=================================================================================================\n",
      "= Flip Testing irrelevant | Accuracy Threshold: 0.85 | Bias Threshold: 0.05 =\n",
      "=================================================================================================\n",
      "Result | Accuracy: 0.8805 (pass) | Checked: 0.0000 (pass)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for problem_type in problem_cols:\n",
    "    passes, acc_passes = flip_testing( model=model, X=features, y=target, columns=problem_cols[problem_type], title=problem_type, tries=5, accuracy_threshold=0.85, bias_threshold=0.05 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219de17-f08b-4543-9f06-5e09c5425c8a",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5e7e40c-436a-4eaf-b7eb-d09e4fe0311b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m onnx_good = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m onnx_program.save(\u001b[33m\"\u001b[39m\u001b[33m./models/good_model.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m onnx_model = onnx.load(\u001b[33m\"\u001b[39m\u001b[33m./models/good_model.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/onnx/__init__.py:296\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Prepare legacy export parameters for potential fallback\u001b[39;00m\n\u001b[32m    287\u001b[39m     legacy_export_kwargs = {\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m: training,\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moperator_export_type\u001b[39m\u001b[33m\"\u001b[39m: operator_export_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mautograd_inlining\u001b[39m\u001b[33m\"\u001b[39m: autograd_inlining,\n\u001b[32m    294\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_compat.py:82\u001b[39m, in \u001b[36mexport_compat\u001b[39m\u001b[34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, custom_translation_table, dynamic_axes, dynamic_shapes, keep_initializers_as_inputs, external_data, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, legacy_export_kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     dynamic_shapes = dynamic_shapes \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     args, kwargs = \u001b[43m_get_torch_export_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dynamic_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     84\u001b[39m         warnings.warn(\n\u001b[32m     85\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m# \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdynamic_axes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not recommended when dynamo=True, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mand may lead to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorch._dynamo.exc.UserError: Constraints violated.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m     90\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_compat.py:36\u001b[39m, in \u001b[36m_get_torch_export_args\u001b[39m\u001b[34m(args, kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_torch_export_args\u001b[39m(\n\u001b[32m     32\u001b[39m     args: \u001b[38;5;28mtuple\u001b[39m[Any, ...],\n\u001b[32m     33\u001b[39m     kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     34\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[Any, ...], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m     35\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Obtain the arguments for torch.onnx.export from the model and the input arguments.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[-\u001b[32m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     37\u001b[39m         kwargs = args[-\u001b[32m1\u001b[39m]\n\u001b[32m     38\u001b[39m         args = args[:-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "onnx_good = torch.onnx.export( model, features.values, dynamo=True)\n",
    "onnx_program.save(\"./models/good_model.onnx\")\n",
    "onnx_model = onnx.load(\"./models/good_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "session = onnxruntime.InferenceSession(\n",
    "    \"./models/good_model.onnx\", providers=[\"CUDAExecutionProvider\"]\n",
    ")\n",
    "y_pred_onnx = session.run(None, features.values.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the model to ONNX\n",
    "#onnx_model = convert_sklearn(\n",
    "#    pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "#    target_opset=12)\n",
    "\n",
    "# Let's check the accuracy of the converted model\n",
    "#sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "#y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "#accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "#print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model\n",
    "#onnx.save(onnx_model, \"model/gboost.onnx\")\n",
    "\n",
    "# Let's load the model\n",
    "#new_session = rt.InferenceSession(\"model/gboost.onnx\")\n",
    "\n",
    "# Let's predict the target\n",
    "#y_pred_onnx2 =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "#accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx2[0])\n",
    "#print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
