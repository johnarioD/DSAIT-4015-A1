{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647a5379",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa476b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "#from skl2onnx.common.data_types import FloatTensorType\n",
    "#from skl2onnx import to_onnx\n",
    "#from skl2onnx import convert_sklearn\n",
    "\n",
    "random_state_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e81b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "\n",
    "# Let's specify the features and the target\n",
    "target = data['checked']\n",
    "features = data.drop(columns=['checked', 'Ja', 'Nee' ])\n",
    "features = features.astype(np.float32)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96ae1f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_problematic_columns( data ):\n",
    "    psychological_features = []\n",
    "    medical_features = [ 'belemmering_hist_verslavingsproblematiek' ]\n",
    "    racial_features = ['ontheffing_reden_hist_sociale_gronden']\n",
    "    subjective_features = [ 'competentie_ethisch_en_integer_handelen', 'competentie_gedrevenheid_en_ambitie_tonen', 'competentie_met_druk_en_tegenslag_omgaan', 'competentie_omgaan_met_verandering_en_aanpassen',\n",
    "                            'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km', 'persoonlijke_eigenschappen_uitstroom_verw_vlgs_klant', 'afspraak_aantal_woorden', 'afspraak_laatstejaar_aantal_woorden',\n",
    "                            'competentie_other', 'competentie_overtuigen_en_beÃ¯nvloeden'\n",
    "                          ]\n",
    "    age_features = ['persoon_leeftijd_bij_onderzoek']\n",
    "    gender_features = ['persoon_geslacht_vrouw']\n",
    "    relationship_features = []\n",
    "    irrelevant_features = [ 'persoonlijke_eigenschappen_hobbies_sport' ]\n",
    "\n",
    "    for col in data.columns:\n",
    "        if 'relatie' in col:\n",
    "            relationship_features.append( col )\n",
    "        elif 'persoonlijke' in col:\n",
    "            if '_nl_' in col or 'taal' in col:\n",
    "                racial_features.append(col)\n",
    "            elif '_opm' in col:\n",
    "                subjective_features.append(col)\n",
    "        elif 'adres_recenst' in col or 'sociaal' in col or 'taal' in col:\n",
    "            racial_features.append(col)\n",
    "        elif 'medische' in col or 'lichamelijke' in col:\n",
    "            medical_features.append(col)\n",
    "        elif 'psychische' in col:\n",
    "            psychological_features.append(col)\n",
    "\n",
    "    return {\n",
    "            'psychological': psychological_features,\n",
    "            'medical': medical_features,\n",
    "            'racial': racial_features,\n",
    "            'subjective': subjective_features,\n",
    "            'gender': gender_features,\n",
    "            'relationship': relationship_features,\n",
    "            'age': age_features,\n",
    "            'irrelevant': irrelevant_features\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6f7e4",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c5db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_grouping( data, column_set ):\n",
    "    pca = PCA( n_components=1 )\n",
    "    return pca.fit_transform( data[column_set] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5661ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_wise_partition( feature, n_partitions=2, thresholds=None ):\n",
    "    feature = feature.copy()\n",
    "    partitions = []\n",
    "    if thresholds is None:\n",
    "        mn, mx = feature.min(), feature.max()\n",
    "        step = (mx-mn)/n_partitions\n",
    "        thresholds = [ i for i in np.arange( mn, mx + 0.1*step, step ) ]\n",
    "    else:\n",
    "        assert n_partitions+1 == len(thresholds)\n",
    "\n",
    "    for i in range( len(thresholds)-1 ):\n",
    "        idx = np.where( (feature >= thresholds[i]) & ( feature < thresholds[i+1]) )\n",
    "        partitions.append( idx )\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3117aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_columns( data, column_set ):\n",
    "    data = data.copy()\n",
    "    shuffled = data[column_set].sample(frac=1).reset_index(drop=True)\n",
    "    data[column_set] = shuffled\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe8694f-9fd8-4008-8d70-1e13c0a92161",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_cols = get_problematic_columns( features )\n",
    "\n",
    "partitions = {}\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['psychological'] )\n",
    "partitions['psychological'] = n_wise_partition( grouped_subset, 2 ) # well, unwell\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['medical'] )\n",
    "partitions['medical'] = n_wise_partition( grouped_subset, 2 ) # well, unwell\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['racial'] )\n",
    "partitions['racial'] = n_wise_partition( grouped_subset, 4 ) # Germanic language native, Romance native, PIE native, Non-PIE native\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['subjective'] )\n",
    "partitions['subjective'] = n_wise_partition( grouped_subset, 3 ) # Low, Mid, High opinion\n",
    "\n",
    "grouped_subset = features[ problem_cols['gender'][0] ]\n",
    "partitions['gender'] = n_wise_partition( grouped_subset, 2 ) # Male, Female\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['relationship'] )\n",
    "partitions['relationship'] = n_wise_partition( grouped_subset, 3 ) # Small average, large social circle/family\n",
    "\n",
    "grouped_subset = features[ problem_cols['age'][0] ]\n",
    "partitions['age'] = n_wise_partition( grouped_subset, 3, [ 0, 30, 60, 200 ] ) # Young Adult, Adult, Senior\n",
    "\n",
    "grouped_subset = pca_grouping( features, problem_cols['irrelevant'] )\n",
    "partitions['irrelevant'] = n_wise_partition( grouped_subset, 2 ) # Only for sports hobbyists, yes/no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021f086",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa6b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5434ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__( self, architecture, loss, optimizer ):\n",
    "        super().__init__()\n",
    "        self.arch = architecture\n",
    "        self.loss_f = loss\n",
    "        self.optim = optimizer\n",
    "\n",
    "    def forward( self, X ):\n",
    "        return self.arch( X )\n",
    "\n",
    "    def backward( self, y_pred, y ):\n",
    "        loss = self.loss_f( y_pred, y )\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "    def fit( self, X, y, epochs=1000 ):\n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.forward( X )\n",
    "            self.backward( y_pred, y )\n",
    "\n",
    "    def predict( self, X ):\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax( model.forward(X), dim=1 )\n",
    "\n",
    "    def fit_predict( self, X, y, epochs=1000 ):\n",
    "        self.fit( X, y, epochs=epochs )\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47977f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model( model, X, y, epochs=1000 ):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X.values, y.values, test_size=0.2 )\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    y_pred = model.fit_predict( X_train, y_train )\n",
    "    train_accuracy = (y_pred==y_train).float().mean().to(\"cpu\")\n",
    "    print( f\"Train Accuracy of the original model: {train_accuracy}\")\n",
    "\n",
    "    y_pred = model.predict( X_test )\n",
    "    test_accuracy = (y_pred==y_test).float().mean().to(\"cpu\")\n",
    "    print( f\"Test Accuracy of the original model: {test_accuracy}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7dc24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_partitions( model, X, y, partitions, title, accuracy_threshold=0.9, bias_threshold=0.05 ):\n",
    "    passes, idx, accuracy_passes = 0, 0, 0\n",
    "    checked_per_partition = np.empty( len(partitions) )\n",
    "    accuracies = []\n",
    "\n",
    "    print( f\"=================================================================================================\")\n",
    "    print( f\"= Testing {title} | Accuracy Threshold: {accuracy_threshold} | Bias Threshold: {bias_threshold} =\")\n",
    "    print( f\"=================================================================================================\")\n",
    "    for partition in partitions:\n",
    "        X_part = X.iloc[partition[0]]\n",
    "        y_part = y.iloc[partition[0]]\n",
    "        X_part = torch.tensor(X_part.values, dtype=torch.float).to(device)\n",
    "        y_part = torch.tensor(y_part.values, dtype=torch.long).to(device)\n",
    "\n",
    "        y_pred = model.predict(X_part)\n",
    "        accuracy = (y_pred==y_part).float().mean().to(\"cpu\")\n",
    "        accuracy_passes += 1 if accuracy > accuracy_threshold else 0\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        checked_count = ( y_pred == 1 ).float().mean().to(\"cpu\").numpy()\n",
    "        checked_per_partition[idx] = checked_count\n",
    "        print( f\"Partition {idx} | \"\n",
    "               f\"Accuracy: {accuracy:.4f} ({ 'pass' if accuracy >= accuracy_threshold else 'fail'}) | \"\n",
    "               f\"Checked: {checked_count:.4f}\"\n",
    "             )\n",
    "        idx += 1\n",
    "\n",
    "    checked_mean = checked_per_partition.mean()\n",
    "    for i in range(len(checked_per_partition)):\n",
    "        if np.abs( checked_per_partition[i]/checked_mean - 1 ) < bias_threshold:\n",
    "            passes += 1\n",
    "    \n",
    "        \n",
    "    print( f\"Total Passes |\"\n",
    "        f\" Accuracy: {accuracy_passes}/{len(partitions)} |\"\n",
    "        f\" Bias passes: {passes}/{len(partitions)}\\n\" )\n",
    "    return passes, accuracy_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "270b9862-58df-470e-a7cb-504768fd5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metamorphic( model, X, y, columns, title, tries=5, accuracy_threshold=0.9, bias_threshold=0.05 ):\n",
    "    passes, idx, accuracy_passes = 0, 0, 0\n",
    "    checked_per_try = np.empty( tries )\n",
    "    accuracies = []\n",
    "    y = torch.tensor(y.values, dtype=torch.long).to(device)\n",
    "\n",
    "    print( f\"=================================================================================================\")\n",
    "    print( f\"= Testing {title} | Accuracy Threshold: {accuracy_threshold} | Bias Threshold: {bias_threshold} =\")\n",
    "    print( f\"=================================================================================================\")\n",
    "    for _ in range(tries):\n",
    "        X_alt = shuffle_columns( X, columns )\n",
    "        X_alt = torch.tensor(X_alt.values, dtype=torch.float).to(device)\n",
    "\n",
    "        y_pred = model.predict(X_alt)\n",
    "        accuracy = (y_pred==y).float().mean().to(\"cpu\")\n",
    "        accuracy_passes += 1 if accuracy > accuracy_threshold else 0\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        checked_count = ( y_pred == 1 ).float().mean().to(\"cpu\").numpy()\n",
    "        checked_per_try[idx] = checked_count\n",
    "        print( f\"Partition {idx} | \"\n",
    "               f\"Accuracy: {accuracy:.4f} ({ 'pass' if accuracy >= accuracy_threshold else 'fail'}) | \"\n",
    "               f\"Checked: {checked_count:.4f}\"\n",
    "             )\n",
    "        idx += 1\n",
    "\n",
    "    checked_mean = checked_per_try.mean()\n",
    "    for i in range( len(checked_per_try) ):\n",
    "        if np.abs( checked_per_try[i]/checked_mean - 1 ) < bias_threshold:\n",
    "            passes += 1\n",
    "    \n",
    "        \n",
    "    print( f\"Total Passes |\"\n",
    "        f\" Accuracy: {accuracy_passes}/{tries} |\"\n",
    "        f\" Bias passes: {passes}/{tries}\\n\" )\n",
    "    return passes, accuracy_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b96a585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = features.shape\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ( 'linear1', nn.Linear( n_features, 100 ) ),\n",
    "        ( 'activation1', nn.ReLU() ),\n",
    "        ( 'linear2', nn.Linear( 100, 25 ) ),\n",
    "        ( 'activation2', nn.ReLU()),\n",
    "        ( 'linear3', nn.Linear( 25, 10 ) ),\n",
    "        ( 'activation3', nn.ReLU()),\n",
    "        ( 'linear4', nn.Linear( 10, 2 ) )\n",
    "        #( 'activation4', nn.Sigmoid() )\n",
    "    ])\n",
    ").to(device)\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "adam = torch.optim.Adam( mlp.parameters(), lr=1e-3 )\n",
    "\n",
    "# Define a gradient boosting classifier\n",
    "# model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "model = Model( architecture=mlp, loss=cross_entropy, optimizer=adam )\n",
    "\n",
    "# Create a pipeline object with our selector and classifier\n",
    "# NOTE: You can create custom pipeline objects but they must be registered to onnx or it will not recognise them\n",
    "# Because of this we recommend using the onnx known objects as defined in the documentation\n",
    "# pipeline = Pipeline(steps=[('feature selection', selector), ('classification', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ee75cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of the original model: 0.8923268914222717\n",
      "Test Accuracy of the original model: 0.889269232749939\n"
     ]
    }
   ],
   "source": [
    "model = train_eval_model( model=model, X=features, y=target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0042e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================\n",
      "= Testing psychological | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8641 (pass) | Checked: 0.0761\n",
      "Partition 1 | Accuracy: 0.8929 (pass) | Checked: 0.0658\n",
      "Total Passes | Accuracy: 2/2 | Bias passes: 2/2 (mean: 0.07096156850457191)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing medical | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8885 (pass) | Checked: 0.0717\n",
      "Partition 1 | Accuracy: 0.9109 (pass) | Checked: 0.0338\n",
      "Total Passes | Accuracy: 2/2 | Bias passes: 0/2 (mean: 0.05275589041411877)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing racial | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8645 (pass) | Checked: 0.0947\n",
      "Partition 1 | Accuracy: 0.9236 (pass) | Checked: 0.0329\n",
      "Partition 2 | Accuracy: 0.9481 (pass) | Checked: 0.0098\n",
      "Partition 3 | Accuracy: 0.9323 (pass) | Checked: 0.0053\n",
      "Total Passes | Accuracy: 4/4 | Bias passes: 1/4 (mean: 0.035671486519277096)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing subjective | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8860 (pass) | Checked: 0.0713\n",
      "Partition 1 | Accuracy: 0.9168 (pass) | Checked: 0.0445\n",
      "Partition 2 | Accuracy: 0.9229 (pass) | Checked: 0.0169\n",
      "Total Passes | Accuracy: 3/3 | Bias passes: 1/3 (mean: 0.04422403002778689)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing gender | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8919 (pass) | Checked: 0.0696\n",
      "Partition 1 | Accuracy: nan (fail) | Checked: nan\n",
      "Total Passes | Accuracy: 1/2 | Bias passes: 0/2 (mean: nan)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing relationship | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8930 (pass) | Checked: 0.0654\n",
      "Partition 1 | Accuracy: 0.8799 (pass) | Checked: 0.0746\n",
      "Partition 2 | Accuracy: 0.8152 (fail) | Checked: 0.0870\n",
      "Total Passes | Accuracy: 2/3 | Bias passes: 1/3 (mean: 0.07566845913728078)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing age | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.7995 (fail) | Checked: 0.2969\n",
      "Partition 1 | Accuracy: 0.9014 (pass) | Checked: 0.0681\n",
      "Partition 2 | Accuracy: 0.8668 (pass) | Checked: 0.0082\n",
      "Total Passes | Accuracy: 2/3 | Bias passes: 0/3 (mean: 0.12438852339982986)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing irrelevant | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8903 (pass) | Checked: 0.0620\n",
      "Partition 1 | Accuracy: nan (fail) | Checked: nan\n",
      "Total Passes | Accuracy: 1/2 | Bias passes: 0/2 (mean: nan)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for problem_type in problem_cols:\n",
    "    passes, acc_passes = test_partitions( model=model, X=features, y=target, partitions=partitions[problem_type], title=problem_type, accuracy_threshold=0.85, bias_threshold=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b4dd9ac-cd43-4d81-ac77-8021105f548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================\n",
      "= Testing psychological | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8887 (pass) | Checked: 0.0649\n",
      "Partition 1 | Accuracy: 0.8898 (pass) | Checked: 0.0654\n",
      "Partition 2 | Accuracy: 0.8893 (pass) | Checked: 0.0647\n",
      "Partition 3 | Accuracy: 0.8889 (pass) | Checked: 0.0645\n",
      "Partition 4 | Accuracy: 0.8891 (pass) | Checked: 0.0649\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.06486461609601975)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing medical | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8811 (pass) | Checked: 0.0604\n",
      "Partition 1 | Accuracy: 0.8812 (pass) | Checked: 0.0609\n",
      "Partition 2 | Accuracy: 0.8808 (pass) | Checked: 0.0608\n",
      "Partition 3 | Accuracy: 0.8807 (pass) | Checked: 0.0606\n",
      "Partition 4 | Accuracy: 0.8808 (pass) | Checked: 0.0612\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.060776925086975096)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing racial | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8805 (pass) | Checked: 0.0589\n",
      "Partition 1 | Accuracy: 0.8806 (pass) | Checked: 0.0588\n",
      "Partition 2 | Accuracy: 0.8810 (pass) | Checked: 0.0593\n",
      "Partition 3 | Accuracy: 0.8804 (pass) | Checked: 0.0591\n",
      "Partition 4 | Accuracy: 0.8805 (pass) | Checked: 0.0595\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.059121540188789366)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing subjective | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8891 (pass) | Checked: 0.0704\n",
      "Partition 1 | Accuracy: 0.8878 (pass) | Checked: 0.0707\n",
      "Partition 2 | Accuracy: 0.8884 (pass) | Checked: 0.0702\n",
      "Partition 3 | Accuracy: 0.8881 (pass) | Checked: 0.0704\n",
      "Partition 4 | Accuracy: 0.8879 (pass) | Checked: 0.0693\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.07020000219345093)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing gender | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8917 (pass) | Checked: 0.0666\n",
      "Partition 1 | Accuracy: 0.8918 (pass) | Checked: 0.0666\n",
      "Partition 2 | Accuracy: 0.8917 (pass) | Checked: 0.0664\n",
      "Partition 3 | Accuracy: 0.8918 (pass) | Checked: 0.0665\n",
      "Partition 4 | Accuracy: 0.8916 (pass) | Checked: 0.0666\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.06652923375368118)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing relationship | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8753 (pass) | Checked: 0.0698\n",
      "Partition 1 | Accuracy: 0.8752 (pass) | Checked: 0.0712\n",
      "Partition 2 | Accuracy: 0.8759 (pass) | Checked: 0.0698\n",
      "Partition 3 | Accuracy: 0.8755 (pass) | Checked: 0.0703\n",
      "Partition 4 | Accuracy: 0.8755 (pass) | Checked: 0.0700\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.07023077011108399)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing age | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8837 (pass) | Checked: 0.0568\n",
      "Partition 1 | Accuracy: 0.8837 (pass) | Checked: 0.0568\n",
      "Partition 2 | Accuracy: 0.8840 (pass) | Checked: 0.0567\n",
      "Partition 3 | Accuracy: 0.8836 (pass) | Checked: 0.0568\n",
      "Partition 4 | Accuracy: 0.8842 (pass) | Checked: 0.0571\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.05684461742639542)\n",
      "\n",
      "=================================================================================================\n",
      "= Testing irrelevant | Accuracy Threshold: 0.85 | Bias Threshold: 0.1 =\n",
      "=================================================================================================\n",
      "Partition 0 | Accuracy: 0.8917 (pass) | Checked: 0.0663\n",
      "Partition 1 | Accuracy: 0.8917 (pass) | Checked: 0.0664\n",
      "Partition 2 | Accuracy: 0.8916 (pass) | Checked: 0.0662\n",
      "Partition 3 | Accuracy: 0.8918 (pass) | Checked: 0.0663\n",
      "Partition 4 | Accuracy: 0.8918 (pass) | Checked: 0.0663\n",
      "Total Passes | Accuracy: 5/5 | Bias passes: 5/5 (mean: 0.06630615592002868)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for problem_type in problem_cols:\n",
    "    passes, acc_passes = test_metamorphic( model=model, X=features, y=target, columns=problem_cols[problem_type], title=problem_type, tries=5, accuracy_threshold=0.85, bias_threshold=0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4219de17-f08b-4543-9f06-5e09c5425c8a",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5e7e40c-436a-4eaf-b7eb-d09e4fe0311b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m onnx_good = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m onnx_program.save(\u001b[33m\"\u001b[39m\u001b[33m./models/good_model.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m onnx_model = onnx.load(\u001b[33m\"\u001b[39m\u001b[33m./models/good_model.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/onnx/__init__.py:296\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Prepare legacy export parameters for potential fallback\u001b[39;00m\n\u001b[32m    287\u001b[39m     legacy_export_kwargs = {\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m: training,\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moperator_export_type\u001b[39m\u001b[33m\"\u001b[39m: operator_export_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    293\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mautograd_inlining\u001b[39m\u001b[33m\"\u001b[39m: autograd_inlining,\n\u001b[32m    294\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy_export_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_compat.py:82\u001b[39m, in \u001b[36mexport_compat\u001b[39m\u001b[34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, custom_translation_table, dynamic_axes, dynamic_shapes, keep_initializers_as_inputs, external_data, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, legacy_export_kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     dynamic_shapes = dynamic_shapes \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     args, kwargs = \u001b[43m_get_torch_export_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dynamic_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     84\u001b[39m         warnings.warn(\n\u001b[32m     85\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m# \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdynamic_axes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not recommended when dynamo=True, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mand may lead to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorch._dynamo.exc.UserError: Constraints violated.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m     90\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_compat.py:36\u001b[39m, in \u001b[36m_get_torch_export_args\u001b[39m\u001b[34m(args, kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_torch_export_args\u001b[39m(\n\u001b[32m     32\u001b[39m     args: \u001b[38;5;28mtuple\u001b[39m[Any, ...],\n\u001b[32m     33\u001b[39m     kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     34\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[Any, ...], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m     35\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Obtain the arguments for torch.onnx.export from the model and the input arguments.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[-\u001b[32m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     37\u001b[39m         kwargs = args[-\u001b[32m1\u001b[39m]\n\u001b[32m     38\u001b[39m         args = args[:-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "onnx_good = torch.onnx.export( model, features.values, dynamo=True)\n",
    "onnx_program.save(\"./models/good_model.onnx\")\n",
    "onnx_model = onnx.load(\"./models/good_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "session = onnxruntime.InferenceSession(\n",
    "    \"./models/good_model.onnx\", providers=[\"CUDAExecutionProvider\"]\n",
    ")\n",
    "y_pred_onnx = session.run(None, features.values.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the model to ONNX\n",
    "#onnx_model = convert_sklearn(\n",
    "#    pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "#    target_opset=12)\n",
    "\n",
    "# Let's check the accuracy of the converted model\n",
    "#sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "#y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "#accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "#print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model\n",
    "#onnx.save(onnx_model, \"model/gboost.onnx\")\n",
    "\n",
    "# Let's load the model\n",
    "#new_session = rt.InferenceSession(\"model/gboost.onnx\")\n",
    "\n",
    "# Let's predict the target\n",
    "#y_pred_onnx2 =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "#accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx2[0])\n",
    "#print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
